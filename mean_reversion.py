# -*- coding: utf-8 -*-
"""
SISTEMA DE TRADING MULTI-ACTIVO CON WALK-FORWARD VALIDATION Y BACKTESTING
================================================================================
Arquitectura:
1. Pipeline completo sin look-ahead bias
2. Validaci√≥n Walk-Forward con regresi√≥n log√≠stica regularizada
3. Sistema de scoring probabil√≠stico (no umbrales r√≠gidos)
4. Backtesting de 3 meses con m√©tricas realistas
5. Gesti√≥n de riesgo basada en ATR din√°mico

Caracter√≠sticas:
- Eliminaci√≥n completa de look-ahead bias
- Modelos entrenados solo con datos hist√≥ricos disponibles
- Scoring continuo (0-100%) en lugar de clasificaci√≥n binaria
- Separaci√≥n estricta entre entrenamiento, validaci√≥n y testing
- M√©tricas out-of-sample exclusivamente
"""

import yfinance as yf
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import pytz
import time
import warnings
import os
import requests
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import matplotlib.pyplot as plt
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# ============================================
# 1. CONFIGURACI√ìN DEL SISTEMA
# ============================================
print("=" * 80)
print("SISTEMA DE TRADING CON VALIDACI√ìN WALK-FORWARD Y BACKTESTING")
print("=" * 80)

# Configuraci√≥n de tiempo
colombia_tz = pytz.timezone('America/Bogota')
#FECHA_ACTUAL = datetime(2025, 9, 24, 14, 0, tzinfo=colombia_tz)
FECHA_ACTUAL = datetime.now(colombia_tz)
FECHA_INICIO_BACKTEST = FECHA_ACTUAL - timedelta(days=90)  # 3 meses para backtesting
FECHA_INICIO_ENTRENAMIENTO = FECHA_INICIO_BACKTEST - timedelta(days=365)  # 1 a√±o antes para entrenamiento

# Par√°metros del sistema
INTERVALO = "1h"
ACTIVOS = ["BTC-USD"]  # Puedes agregar m√°s activos aqu√≠

# Par√°metros de Mean Reversion
VENTANA_MR = 60
K_DESVIACIONES = 2.5

# Par√°metros de gesti√≥n de riesgo
ATR_PERIODO = 14
MULTIPLICADOR_SL = 1.5
MULTIPLICADOR_TP = 2.55
RATIO_MINIMO_RR = 1.7

# Horizontes de predicci√≥n (en horas)
HORIZONTES = [4, 8, 12, 24, 48]

# Configuraci√≥n Walk-Forward
N_FOLDS_WF = 5  # N√∫mero de folds para walk-forward
TAMANIO_TEST_WF = 0.2  # 20% para test en cada fold

# Configuraci√≥n modelos
FEATURES_TECNICAS = [
    'RSI', 'Volatilidad', 'Distancia_MA', 'Rango_HL',
    'Aceleracion_Retorno', 'RSI_lag1', 'Volatilidad_lag1',
    'ADX', 'Posicion_BB', 'ATR', 'ATR_porcentaje'
]

FEATURES_CALIDAD = [
    'RSI', 'Volatilidad', 'Distancia_MA', 'Rango_HL',
    'Aceleracion_Retorno', 'ADX', 'Posicion_BB', 'ATR',
    'ATR_porcentaje', 'Retorno_Log', 'Intensidad_Anomalia', 
    'Volumen_Relativo', 'Distancia_Banda', 'Momento_Relativo'
]

print(f"\nüìä CONFIGURACI√ìN DEL SISTEMA:")
print(f" Per√≠odo backtesting: {FECHA_INICIO_BACKTEST.date()} - {FECHA_ACTUAL.date()}")
print(f" Per√≠odo entrenamiento: {FECHA_INICIO_ENTRENAMIENTO.date()} - {FECHA_INICIO_BACKTEST.date()}")
print(f" Activoss: {len(ACTIVOS)}")
print(f" Validaci√≥n Walk-Forward: {N_FOLDS_WF} folds")
print(f" Modelo principal: Logistic Regression (L2)")
print(f" Sistema de scoring: Probabil√≠stico (0-100%)")

# ============================================
# 2. FUNCIONES DE C√ÅLCULO DE INDICADORES
# ============================================

def calcular_indicadores_tecnicos(df):
    """
    Calcula todos los indicadores t√©cnicos sin look-ahead bias.
    Solo utiliza datos disponibles hasta cada punto en el tiempo.
    """
    df = df.copy()
    
    # 1. Retorno logar√≠tmico (base para muchos indicadores)
    df['Retorno_Log'] = np.log(df['Close'] / df['Close'].shift(1))
    
    # 2. Mean Reversion con ventana adaptativa
    ventana_efectiva = min(VENTANA_MR, len(df) // 4)
    if ventana_efectiva < 10:
        ventana_efectiva = 10
    
    df['Media_Movil_Retorno'] = df['Retorno_Log'].rolling(
        window=ventana_efectiva, min_periods=5).mean()
    df['Desviacion_Retorno'] = df['Retorno_Log'].rolling(
        window=ventana_efectiva, min_periods=5).std()
    
    df['Banda_Superior_MR'] = df['Media_Movil_Retorno'] + K_DESVIACIONES * df['Desviacion_Retorno']
    df['Banda_Inferior_MR'] = df['Media_Movil_Retorno'] - K_DESVIACIONES * df['Desviacion_Retorno']
    
    # 3. Detecci√≥n de anomal√≠as (solo basado en datos pasados)
    df['Anomalia'] = (
        (df['Retorno_Log'] > df['Banda_Superior_MR']) | 
        (df['Retorno_Log'] < df['Banda_Inferior_MR'])
    )
    
    # 4. Direcci√≥n de la se√±al (LONG/SHORT)
    df['Senal_MR'] = np.where(
        df['Retorno_Log'] < df['Banda_Inferior_MR'], 
        'LONG', 
        np.where(df['Retorno_Log'] > df['Banda_Superior_MR'], 'SHORT', 'NEUTRAL')
    )
    
    # 5. Intensidad de la anomal√≠a (z-score)
    df['Intensidad_Anomalia'] = (
        (df['Retorno_Log'] - df['Media_Movil_Retorno']) / df['Desviacion_Retorno']
    ).abs()
    
    # 6. Distancia a la banda (para caracter√≠sticas de calidad)
    df['Distancia_Banda'] = np.where(
        df['Retorno_Log'] > df['Banda_Superior_MR'],
        (df['Retorno_Log'] - df['Banda_Superior_MR']) / df['Desviacion_Retorno'],
        np.where(df['Retorno_Log'] < df['Banda_Inferior_MR'],
                (df['Banda_Inferior_MR'] - df['Retorno_Log']) / df['Desviacion_Retorno'],
                0)
    )
    
    # 7. ATR (Average True Range) - CORREGIDO
    # Calcular True Range
    df['TR'] = np.maximum(
        df['High'] - df['Low'],
        np.maximum(
            abs(df['High'] - df['Close'].shift(1)),
            abs(df['Low'] - df['Close'].shift(1))
        )
    )
    
    # Calcular ATR como media m√≥vil del TR
    df['ATR'] = df['TR'].rolling(window=ATR_PERIODO, min_periods=5).mean()
    
    # Calcular ATR como porcentaje del precio
    df['ATR_porcentaje'] = (df['ATR'] / df['Close']) * 100
    
    # 8. RSI
    delta = df['Close'].diff()
    ganancia = (delta.where(delta > 0, 0)).rolling(window=14, min_periods=5).mean()
    perdida = (-delta.where(delta < 0, 0)).rolling(window=14, min_periods=5).mean()
    rs = ganancia / perdida
    df['RSI'] = 100 - (100 / (1 + rs))
    df['RSI_lag1'] = df['RSI'].shift(1)
    
    # 9. Volatilidad (desviaci√≥n est√°ndar de retornos)
    df['Volatilidad'] = df['Retorno_Log'].rolling(window=24, min_periods=5).std()
    df['Volatilidad_lag1'] = df['Volatilidad'].shift(1)
    
    # 10. Distancia a la media m√≥vil
    media_50 = df['Close'].rolling(window=50, min_periods=10).mean()
    df['Distancia_MA'] = (df['Close'] - media_50) / media_50
    
    # 11. Rango High-Low normalizado
    df['Rango_HL'] = (df['High'] - df['Low']) / df['Close']
    
    # 12. Aceleraci√≥n del retorno
    df['Aceleracion_Retorno'] = df['Retorno_Log'].diff()
    
    # 13. ADX (simplificado como ratio de volatilidad)
    df['ADX'] = df['Close'].rolling(14, min_periods=5).std() / df['Close'].rolling(50, min_periods=10).std()
    
    # 14. Bandas de Bollinger
    media_20 = df['Close'].rolling(window=20, min_periods=5).mean()
    std_20 = df['Close'].rolling(window=20, min_periods=5).std()
    df['BB_superior'] = media_20 + 2 * std_20
    df['BB_inferior'] = media_20 - 2 * std_20
    df['Posicion_BB'] = (df['Close'] - df['BB_inferior']) / (df['BB_superior'] - df['BB_inferior'])
    
    # 15. Momento relativo (retorno de las √∫ltimas N velas)
    df['Momento_Relativo'] = df['Close'] / df['Close'].shift(5) - 1
    
    # 16. Volumen relativo (si est√° disponible)
    if 'Volume' in df.columns:
        media_volumen = df['Volume'].rolling(window=20, min_periods=5).mean()
        df['Volumen_Relativo'] = df['Volume'] / media_volumen
    else:
        df['Volumen_Relativo'] = 1.0
    
    # 17. Targets para horizontes futuros
    for horizonte in HORIZONTES:
        retorno_futuro = df['Close'].shift(-horizonte) / df['Close'] - 1
        df[f'Target_{horizonte}h'] = (retorno_futuro > 0).astype(int)
    
    # Eliminar columnas temporales
    if 'TR' in df.columns:
        df = df.drop(columns=['TR'])
    
    return df.dropna()

def calcular_niveles_riesgo_atr(precio_actual, atr, direccion):
    """
    Calcula niveles de Stop Loss y Take Profit basados en ATR.
    """
    if direccion == 'LONG':
        stop_loss = precio_actual - (MULTIPLICADOR_SL * atr)
        take_profit = precio_actual + (MULTIPLICADOR_TP * atr)
    else:  # SHORT
        stop_loss = precio_actual + (MULTIPLICADOR_SL * atr)
        take_profit = precio_actual - (MULTIPLICADOR_TP * atr)
    
    riesgo = abs(precio_actual - stop_loss)
    recompensa = abs(take_profit - precio_actual)
    ratio_rr = recompensa / riesgo if riesgo > 0 else 0
    
    return {
        'stop_loss': stop_loss,
        'take_profit': take_profit,
        'riesgo': riesgo,
        'recompensa': recompensa,
        'ratio_rr': ratio_rr,
        'atr_valor': atr
    }

# ============================================
# 3. FUNCIONES DE VALIDACI√ìN WALK-FORWARD
# ============================================

def crear_splits_walkforward(datos, n_folds=N_FOLDS_WF, test_size=TAMANIO_TEST_WF):
    """
    Crea splits temporales para validaci√≥n walk-forward.
    Garantiza que no haya look-ahead bias.
    """
    splits = []
    datos_ordenados = datos.sort_index()
    n_total = len(datos_ordenados)
    n_test = int(n_total * test_size)
    
    # Si no hay suficientes datos, reducir folds
    if n_total < n_folds * n_test * 2:
        n_folds = max(2, n_total // (2 * n_test))
    
    for i in range(n_folds):
        # Porcentajes crecientes para train
        train_end_idx = int(n_total * (0.5 + 0.3 * (i / n_folds)))
        test_start_idx = train_end_idx
        test_end_idx = min(test_start_idx + n_test, n_total)
        
        if test_end_idx - test_start_idx < 10:  # M√≠nimo para test
            continue
        
        train_data = datos_ordenados.iloc[:train_end_idx]
        test_data = datos_ordenados.iloc[test_start_idx:test_end_idx]
        
        splits.append({
            'train': train_data,
            'test': test_data,
            'train_start': train_data.index[0],
            'train_end': train_data.index[-1],
            'test_start': test_data.index[0],
            'test_end': test_data.index[-1]
        })
    
    return splits

def entrenar_modelo_walkforward(datos_completos, features, target_col, 
                               modelo_class=LogisticRegression, 
                               param_grid=None):
    """
    Entrena modelo con validaci√≥n walk-forward.
    Retorna m√©tricas out-of-sample y modelo final.
    """
    if param_grid is None:
        param_grid = {
            'C': 0.1,
            'penalty': 'l2',
            'max_iter': 1000,
            'class_weight': 'balanced',
            'random_state': 42
        }
    
    splits = crear_splits_walkforward(datos_completos)
    
    if len(splits) == 0:
        print("‚ö†Ô∏è No se pudieron crear splits walk-forward. Usando split simple 80/20.")
        # Fallback a split simple
        split_idx = int(len(datos_completos) * 0.8)
        splits = [{
            'train': datos_completos.iloc[:split_idx],
            'test': datos_completos.iloc[split_idx:],
            'train_start': datos_completos.index[0],
            'train_end': datos_completos.index[split_idx-1],
            'test_start': datos_completos.index[split_idx],
            'test_end': datos_completos.index[-1]
        }]
    
    metricas_folds = []
    modelos = []
    scalers = []
    
    print(f"\nüîß Entrenando con {len(splits)} folds walk-forward...")
    
    for idx, split in enumerate(splits, 1):
        X_train = split['train'][features]
        y_train = split['train'][target_col]
        X_test = split['test'][features]
        y_test = split['test'][target_col]
        
        # Verificar que tenemos datos suficientes
        if len(X_train) < 10 or len(X_test) < 5:
            print(f"‚ö†Ô∏è Fold {idx}: Datos insuficientes. Saltando...")
            continue
        
        # Verificar que todas las features existan
        missing_features = [f for f in features if f not in X_train.columns]
        if missing_features:
            print(f"‚ö†Ô∏è Fold {idx}: Features faltantes: {missing_features}. Saltando...")
            continue
        
        # Escalado robusto (menos sensible a outliers)
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Entrenar modelo
        if modelo_class == LogisticRegression:
            modelo = modelo_class(**param_grid)
        else:
            modelo = modelo_class(**param_grid)
        
        try:
            modelo.fit(X_train_scaled, y_train)
        except Exception as e:
            print(f"‚ùå Fold {idx}: Error entrenando modelo: {e}")
            continue
        
        # Predecir en test
        y_pred = modelo.predict(X_test_scaled)
        
        # Calcular m√©tricas
        if len(np.unique(y_test)) > 1:
            try:
                y_pred_proba = modelo.predict_proba(X_test_scaled)[:, 1]
                accuracy = accuracy_score(y_test, y_pred)
                precision = precision_score(y_test, y_pred, zero_division=0)
                recall = recall_score(y_test, y_pred, zero_division=0)
                f1 = f1_score(y_test, y_pred, zero_division=0)
                auc = roc_auc_score(y_test, y_pred_proba)
            except:
                accuracy = precision = recall = f1 = auc = 0.0
        else:
            accuracy = precision = recall = f1 = auc = 0.0
        
        metricas_folds.append({
            'fold': idx,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'auc': auc,
            'train_size': len(X_train),
            'test_size': len(X_test),
            'train_period': f"{split['train_start'].date()} a {split['train_end'].date()}",
            'test_period': f"{split['test_start'].date()} a {split['test_end'].date()}"
        })
        
        modelos.append(modelo)
        scalers.append(scaler)
        
        print(f" Fold {idx}: Test AUC={auc:.3f}, F1={f1:.3f}, "
              f"Train={len(X_train)} registros, Test={len(X_test)} registros")
    
    if not metricas_folds:
        print("‚ùå No se pudo entrenar ning√∫n fold. Usando modelo simple.")
        return None
    
    # Promediar m√©tricas de todos los folds
    metricas_promedio = {
        'accuracy': np.mean([m['accuracy'] for m in metricas_folds]),
        'precision': np.mean([m['precision'] for m in metricas_folds]),
        'recall': np.mean([m['recall'] for m in metricas_folds]),
        'f1': np.mean([m['f1'] for m in metricas_folds]),
        'auc': np.mean([m['auc'] for m in metricas_folds])
    }
    
    # Entrenar modelo final con todos los datos hist√≥ricos
    print("\nüéØ Entrenando modelo final con todos los datos hist√≥ricos...")
    X_final = datos_completos[features]
    y_final = datos_completos[target_col]
    
    # Verificar que todas las features existan
    missing_features = [f for f in features if f not in X_final.columns]
    if missing_features:
        print(f"‚ùå Features faltantes en datos finales: {missing_features}")
        # Crear features faltantes con valor 0
        for f in missing_features:
            X_final[f] = 0
    
    scaler_final = RobustScaler()
    X_final_scaled = scaler_final.fit_transform(X_final)
    
    if modelo_class == LogisticRegression:
        modelo_final = modelo_class(**param_grid)
    else:
        modelo_final = modelo_class(**param_grid)
    
    modelo_final.fit(X_final_scaled, y_final)
    
    return {
        'modelo': modelo_final,
        'scaler': scaler_final,
        'metricas_folds': metricas_folds,
        'metricas_promedio': metricas_promedio,
        'modelos_folds': modelos,
        'scalers_folds': scalers
    }

# ============================================
# 4. PIPELINE DE ENTRENAMIENTO COMPLETO
# ============================================

def pipeline_entrenamiento_completo():
    """
    Pipeline completo de entrenamiento sin look-ahead bias.
    """
    print("\n" + "="*80)
    print("FASE 1: PREPARACI√ìN DE DATOS HIST√ìRICOS")
    print("="*80)
    
    # Descargar datos hist√≥ricos para entrenamiento
    datos_entrenamiento = []
    
    for activo in ACTIVOS:
        print(f"\nüìä Descargando {activo} para entrenamiento...")
        
        # Descargar desde inicio entrenamiento hasta inicio backtest
        try:
            datos = yf.download(
                activo, 
                start=FECHA_INICIO_ENTRENAMIENTO,
                end=FECHA_INICIO_BACKTEST,
                interval=INTERVALO,
                progress=False
            )
        except Exception as e:
            print(f"‚ùå Error descargando {activo}: {e}")
            continue
        
        if datos.empty:
            print(f"‚ö†Ô∏è Sin datos para {activo}")
            continue
        
        # Limpiar columnas MultiIndex si es necesario
        if isinstance(datos.columns, pd.MultiIndex):
            datos.columns = datos.columns.droplevel(1)
        
        # Verificar que tengamos las columnas necesarias
        columnas_necesarias = ['Open', 'High', 'Low', 'Close']
        if not all(col in datos.columns for col in columnas_necesarias):
            print(f"‚ö†Ô∏è {activo} no tiene todas las columnas necesarias")
            continue
        
        # Procesar datos
        datos_procesados = calcular_indicadores_tecnicos(datos)
        datos_procesados['Activo'] = activo
        
        # Filtrar solo anomal√≠as para an√°lisis
        anomalias = datos_procesados[datos_procesados['Anomalia']].copy()
        
        # Calcular niveles de riesgo para cada anomal√≠a
        rr_ratios = []
        for idx, fila in anomalias.iterrows():
            niveles = calcular_niveles_riesgo_atr(
                fila['Close'], 
                fila['ATR'], 
                fila['Senal_MR']
            )
            rr_ratios.append(niveles['ratio_rr'])
        
        datos_procesados['Ratio_RR'] = np.nan
        datos_procesados.loc[anomalias.index, 'Ratio_RR'] = rr_ratios
        
        datos_entrenamiento.append(datos_procesados)
        
        print(f"‚úÖ {activo}: {len(datos_procesados)} registros, "
              f"{len(anomalias)} anomal√≠as")
    
    if not datos_entrenamiento:
        print("‚ùå ERROR: No se descargaron datos de ning√∫n activo")
        return None
    
    datos_combinados = pd.concat(datos_entrenamiento, axis=0)
    
    print(f"\nüìà DATASET FINAL DE ENTRENAMIENTO:")
    print(f" Total registros: {len(datos_combinados):,}")
    print(f" Total anomal√≠as: {datos_combinados['Anomalia'].sum():,}")
    print(f" Activos: {datos_combinados['Activo'].nunique()}")
    
    # ============================================
    # ENTRENAMIENTO DE MODELOS POR HORIZONTE
    # ============================================
    
    print("\n" + "="*80)
    print("FASE 2: ENTRENAMIENTO DE MODELOS POR HORIZONTE")
    print("="*80)
    
    modelos_por_horizonte = {}
    metricas_modelos = {}
    
    for horizonte in HORIZONTES:
        print(f"\nüéØ HORIZONTE {horizonte}h")
        print("-" * 40)
        
        target_col = f'Target_{horizonte}h'
        
        # Filtrar datos donde el target est√° disponible
        datos_horizonte = datos_combinados.dropna(subset=[target_col])
        
        # Verificar que tenemos suficientes datos
        if len(datos_horizonte) < 100:
            print(f"‚ö†Ô∏è Datos insuficientes para horizonte {horizonte}h: {len(datos_horizonte)} registros")
            continue
        
        # Verificar que todas las features existan
        missing_features = [f for f in FEATURES_TECNICAS if f not in datos_horizonte.columns]
        if missing_features:
            print(f"‚ö†Ô∏è Features faltantes para horizonte {horizonte}h: {missing_features}")
            # Crear features faltantes con valor 0
            for f in missing_features:
                datos_horizonte[f] = 0
        
        resultado = entrenar_modelo_walkforward(
            datos_horizonte,
            FEATURES_TECNICAS,
            target_col,
            modelo_class=LogisticRegression,
            param_grid={
                'C': 0.1,
                'penalty': 'l2',
                'max_iter': 1000,
                'class_weight': 'balanced',
                'random_state': 42
            }
        )
        
        if resultado is None:
            print(f"‚ùå No se pudo entrenar modelo para horizonte {horizonte}h")
            continue
        
        # Verificar que el resultado tenga la estructura correcta
        if not isinstance(resultado, dict) or 'modelo' not in resultado or 'scaler' not in resultado:
            print(f"‚ùå Estructura incorrecta del resultado para horizonte {horizonte}h")
            continue
            
        modelos_por_horizonte[horizonte] = {
            'modelo': resultado['modelo'],
            'scaler': resultado['scaler'],
            'metricas': resultado['metricas_promedio']
        }
        
        metricas_modelos[horizonte] = resultado['metricas_promedio']
        
        print(f"‚úÖ Modelo entrenado:")
        print(f"   AUC promedio: {resultado['metricas_promedio']['auc']:.3f}")
        print(f"   F1 promedio: {resultado['metricas_promedio']['f1']:.3f}")
        print(f"   Accuracy: {resultado['metricas_promedio']['accuracy']:.3f}")
    
    if not modelos_por_horizonte:
        print("‚ùå ERROR: No se pudieron entrenar modelos para ning√∫n horizonte")
        return None
    
    # ============================================
    # ENTRENAMIENTO DEL CLASIFICADOR DE CALIDAD
    # ============================================
    
    print("\n" + "="*80)
    print("FASE 3: ENTRENAMIENTO DEL CLASIFICADOR DE CALIDAD")
    print("="*80)
    
    # Preparar dataset de calidad
    # Solo usar anomal√≠as hist√≥ricas que ya sabemos si fueron buenas o malas
    anomalias_historicas = datos_combinados[datos_combinados['Anomalia']].copy()
    
    # Calcular si cada anomal√≠a fue "buena" (ganadora en mayor√≠a de horizontes)
    checks = []
    for horizonte in HORIZONTES:
        target_col = f'Target_{horizonte}h'
        if target_col in anomalias_historicas.columns:
            senal_correcta = (
                ((anomalias_historicas['Senal_MR'] == 'LONG') & (anomalias_historicas[target_col] == 1)) |
                ((anomalias_historicas['Senal_MR'] == 'SHORT') & (anomalias_historicas[target_col] == 0))
            )
            checks.append(senal_correcta.astype(int))
    
    if not checks:
        print("‚ö†Ô∏è No hay checks disponibles para calcular calidad")
        clasificador_calidad = None
    else:
        # Calcular score de calidad basado en performance en todos los horizontes
        checks_df = pd.concat(checks, axis=1)
        checks_df.columns = [f'Check_{h}h' for h in HORIZONTES[:len(checks)]]
        
        anomalias_historicas = pd.concat([anomalias_historicas, checks_df], axis=1)
        anomalias_historicas['Score_Calidad'] = checks_df.mean(axis=1)
        
        # Variable objetivo: 1 si el score de calidad > 0.5, 0 en caso contrario
        anomalias_historicas['Target_Calidad'] = (
            anomalias_historicas['Score_Calidad'] > 0.5
        ).astype(int)
        
        print(f"üìä Dataset de calidad:")
        print(f"   Anomal√≠as totales: {len(anomalias_historicas)}")
        print(f"   Buenas anomal√≠as (score > 0.5): {anomalias_historicas['Target_Calidad'].sum()}")
        print(f"   Malas anomal√≠as: {len(anomalias_historicas) - anomalias_historicas['Target_Calidad'].sum()}")
        
        # Verificar que tenemos suficientes datos
        if len(anomalias_historicas) >= 50 and anomalias_historicas['Target_Calidad'].sum() >= 10:
            # Verificar que todas las features de calidad existan
            missing_features = [f for f in FEATURES_CALIDAD if f not in anomalias_historicas.columns]
            if missing_features:
                print(f"‚ö†Ô∏è Features faltantes en dataset de calidad: {missing_features}")
                # Crear features faltantes con valor 0
                for f in missing_features:
                    anomalias_historicas[f] = 0
            
            # Entrenar clasificador de calidad con walk-forward
            resultado_calidad = entrenar_modelo_walkforward(
                anomalias_historicas,
                FEATURES_CALIDAD,
                'Target_Calidad',
                modelo_class=GradientBoostingClassifier,
                param_grid={
                    'n_estimators': 100,
                    'max_depth': 3,
                    'learning_rate': 0.1,
                    'subsample': 0.8,
                    'random_state': 42
                }
            )
            
            if resultado_calidad is not None:
                clasificador_calidad = {
                    'modelo': resultado_calidad['modelo'],
                    'scaler': resultado_calidad['scaler'],
                    'metricas': resultado_calidad['metricas_promedio']
                }
                
                print(f"‚úÖ Clasificador de calidad entrenado:")
                print(f"   AUC: {resultado_calidad['metricas_promedio']['auc']:.3f}")
                print(f"   F1: {resultado_calidad['metricas_promedio']['f1']:.3f}")
            else:
                print("‚ö†Ô∏è No se pudo entrenar clasificador de calidad")
                clasificador_calidad = None
        else:
            print("‚ö†Ô∏è Insuficientes anomal√≠as para entrenar clasificador de calidad")
            clasificador_calidad = None
    
    # ============================================
    # RESUMEN DEL ENTRENAMIENTO
    # ============================================
    
    print("\n" + "="*80)
    print("RESUMEN DEL ENTRENAMIENTO")
    print("="*80)
    
    for horizonte in modelos_por_horizonte.keys():
        metrica = metricas_modelos[horizonte]
        print(f"Horizonte {horizonte}h: AUC={metrica['auc']:.3f}, "
              f"F1={metrica['f1']:.3f}, Acc={metrica['accuracy']:.3f}")
    
    return {
        'modelos_direccion': modelos_por_horizonte,
        'clasificador_calidad': clasificador_calidad,
        'datos_entrenamiento': datos_combinados,
        'anomalias_historicas': anomalias_historicas if 'anomalias_historicas' in locals() else None
    }

# ============================================
# 5. BACKTESTING RIGUROSO (3 MESES)
# ============================================

def ejecutar_backtesting(modelos_entrenados, clasificador_calidad=None):
    """
    Ejecuta backtesting de 3 meses con datos out-of-sample.
    """
    print("\n" + "="*80)
    print("FASE 4: BACKTESTING DE 3 MESES")
    print("="*80)
    
    resultados_backtest = []
    operaciones = []
    
    for activo in ACTIVOS:
        print(f"\nüìä Backtesting {activo}...")
        
        # Descargar datos de backtesting (√∫ltimos 3 meses)
        try:
            datos_backtest = yf.download(
                activo,
                start=FECHA_INICIO_BACKTEST,
                end=FECHA_ACTUAL,
                interval=INTERVALO,
                progress=False
            )
        except Exception as e:
            print(f"‚ùå Error descargando datos de backtesting para {activo}: {e}")
            continue
        
        if datos_backtest.empty:
            print(f"‚ö†Ô∏è Sin datos para backtesting de {activo}")
            continue
        
        # Limpiar columnas MultiIndex si es necesario
        if isinstance(datos_backtest.columns, pd.MultiIndex):
            datos_backtest.columns = datos_backtest.columns.droplevel(1)
        
        # Calcular indicadores
        datos_backtest = calcular_indicadores_tecnicos(datos_backtest)
        
        if datos_backtest.empty:
            print(f"‚ö†Ô∏è No se pudieron calcular indicadores para {activo}")
            continue
        
        # Simular trading vela por vela
        # Empezar despu√©s de tener suficientes datos para indicadores
        inicio_simulacion = 100
        for i in range(inicio_simulacion, len(datos_backtest) - max(HORIZONTES)):
            fecha_actual = datos_backtest.index[i]
            fila_actual = datos_backtest.iloc[i]
            
            # Verificar si hay anomal√≠a en la vela actual
            if not fila_actual['Anomalia']:
                continue
            
            # ============================================
            # 1. EVALUAR SE√ëAL CON DATOS DISPONIBLES HASTA ESE MOMENTO
            # ============================================
            
            precio_actual = fila_actual['Close']
            atr_actual = fila_actual['ATR']
            senal_mr = fila_actual['Senal_MR']
            
            # Calcular niveles de riesgo
            niveles_riesgo = calcular_niveles_riesgo_atr(
                precio_actual, atr_actual, senal_mr
            )
            
            # Filtrar por ratio R:R m√≠nimo
            if niveles_riesgo['ratio_rr'] < RATIO_MINIMO_RR:
                continue
            
            # ============================================
            # 2. PREDICCIONES POR HORIZONTE
            # ============================================
            
            predicciones = {}
            score_alineamiento = 0
            
            # Verificar que modelos_entrenados tiene la estructura correcta
            if not modelos_entrenados or not isinstance(modelos_entrenados, dict):
                print("‚ö†Ô∏è modelos_entrenados no tiene la estructura correcta")
                continue
            
            for horizonte in modelos_entrenados.keys():
                # Verificar que este horizonte tiene la estructura correcta
                if horizonte not in modelos_entrenados:
                    continue
                    
                modelo_info = modelos_entrenados[horizonte]
                
                # Verificar que modelo_info tiene las claves esperadas
                if not isinstance(modelo_info, dict) or 'modelo' not in modelo_info or 'scaler' not in modelo_info:
                    print(f"‚ö†Ô∏è Estructura incorrecta para horizonte {horizonte}")
                    continue
                
                modelo = modelo_info['modelo']
                scaler = modelo_info['scaler']
                
                # Preparar features para predicci√≥n
                features_actual = []
                for feature in FEATURES_TECNICAS:
                    if feature in fila_actual.index:
                        features_actual.append(fila_actual[feature])
                    else:
                        features_actual.append(0)
                
                features_actual = np.array(features_actual).reshape(1, -1)
                features_scaled = scaler.transform(features_actual)
                
                # Predecir
                try:
                    pred_proba = modelo.predict_proba(features_scaled)[0, 1]
                    prediccion = 1 if pred_proba > 0.5 else 0
                    
                    # Verificar alineamiento con se√±al MR
                    senal_predicha = 'LONG' if prediccion == 1 else 'SHORT'
                    alineado = 1 if senal_predicha == senal_mr else 0
                    
                    predicciones[horizonte] = {
                        'prediccion': senal_predicha,
                        'probabilidad': pred_proba,
                        'alineado': alineado
                    }
                    
                    score_alineamiento += alineado
                except Exception as e:
                    print(f"‚ö†Ô∏è Error en predicci√≥n para horizonte {horizonte}: {e}")
                    continue
            
            if not predicciones:
                continue
                
            score_alineamiento = (score_alineamiento / len(predicciones)) * 100
            
            # ============================================
            # 3. EVALUAR CALIDAD DE LA ANOMAL√çA
            # ============================================
            
            probabilidad_calidad = 0.5  # Default neutral
            
            if clasificador_calidad is not None and isinstance(clasificador_calidad, dict):
                try:
                    # Preparar features para clasificador de calidad
                    features_calidad_actual = []
                    for feature in FEATURES_CALIDAD:
                        if feature in fila_actual.index:
                            features_calidad_actual.append(fila_actual[feature])
                        elif feature == 'Ratio_RR':
                            features_calidad_actual.append(niveles_riesgo['ratio_rr'])
                        else:
                            features_calidad_actual.append(0)
                    
                    features_calidad_actual = np.array(features_calidad_actual).reshape(1, -1)
                    features_scaled = clasificador_calidad['scaler'].transform(features_calidad_actual)
                    probabilidad_calidad = clasificador_calidad['modelo'].predict_proba(features_scaled)[0, 1]
                except Exception as e:
                    print(f"‚ö†Ô∏è Error evaluando calidad: {e}")
                    probabilidad_calidad = 0.5
            
            # ============================================
            # 4. EJECUTAR OPERACI√ìN Y SEGUIR RESULTADOS
            # ============================================
            
            # Simular operaci√≥n para cada horizonte
            for horizonte in predicciones.keys():
                if i + horizonte >= len(datos_backtest):
                    continue
                
                precio_futuro = datos_backtest.iloc[i + horizonte]['Close']
                
                if senal_mr == 'LONG':
                    retorno_real = (precio_futuro - precio_actual) / precio_actual
                    exito = 1 if precio_futuro > precio_actual else 0
                else:  # SHORT
                    retorno_real = (precio_actual - precio_futuro) / precio_actual
                    exito = 1 if precio_futuro < precio_actual else 0
                
                # Verificar stop loss y take profit
                hit_sl = False
                hit_tp = False
                
                # Verificar si se alcanz√≥ SL o TP dentro del horizonte
                for j in range(1, horizonte + 1):
                    if i + j >= len(datos_backtest):
                        break
                    
                    precio_intermedio = datos_backtest.iloc[i + j]['Close']
                    
                    if senal_mr == 'LONG':
                        if precio_intermedio <= niveles_riesgo['stop_loss']:
                            hit_sl = True
                            retorno_real = (niveles_riesgo['stop_loss'] - precio_actual) / precio_actual
                            break
                        elif precio_intermedio >= niveles_riesgo['take_profit']:
                            hit_tp = True
                            retorno_real = (niveles_riesgo['take_profit'] - precio_actual) / precio_actual
                            break
                    else:  # SHORT
                        if precio_intermedio >= niveles_riesgo['stop_loss']:
                            hit_sl = True
                            retorno_real = (precio_actual - niveles_riesgo['stop_loss']) / precio_actual
                            break
                        elif precio_intermedio <= niveles_riesgo['take_profit']:
                            hit_tp = True
                            retorno_real = (precio_actual - niveles_riesgo['take_profit']) / precio_actual
                            break
                
                operacion = {
                    'activo': activo,
                    'fecha': fecha_actual,
                    'senal': senal_mr,
                    'precio_entrada': precio_actual,
                    'precio_salida': precio_futuro,
                    'horizonte': horizonte,
                    'retorno': retorno_real,
                    'exito': exito,
                    'hit_sl': hit_sl,
                    'hit_tp': hit_tp,
                    'ratio_rr': niveles_riesgo['ratio_rr'],
                    'score_alineamiento': score_alineamiento,
                    'probabilidad_calidad': probabilidad_calidad,
                    'atr': atr_actual,
                    'stop_loss': niveles_riesgo['stop_loss'],
                    'take_profit': niveles_riesgo['take_profit']
                }
                
                operaciones.append(operacion)
            
            resultado = {
                'activo': activo,
                'fecha': fecha_actual,
                'senal': senal_mr,
                'precio': precio_actual,
                'ratio_rr': niveles_riesgo['ratio_rr'],
                'score_alineamiento': score_alineamiento,
                'probabilidad_calidad': probabilidad_calidad,
                'n_operaciones': len(predicciones)
            }
            
            resultados_backtest.append(resultado)
    
    # ============================================
    # AN√ÅLISIS DE RESULTADOS DEL BACKTESTING
    # ============================================
    
    if not operaciones:
        print("\n‚ö†Ô∏è No se generaron operaciones en el backtesting")
        return None
    
    df_operaciones = pd.DataFrame(operaciones)
    
    print(f"\nüìä RESULTADOS DEL BACKTESTING:")
    print(f"   Per√≠odo: {FECHA_INICIO_BACKTEST.date()} a {FECHA_ACTUAL.date()}")
    print(f"   Total operaciones simuladas: {len(df_operaciones)}")
    print(f"   Activos: {df_operaciones['activo'].nunique()}")
    
    # M√©tricas generales
    tasa_exito = df_operaciones['exito'].mean()
    retorno_promedio = df_operaciones['retorno'].mean()
    retorno_total = (1 + df_operaciones['retorno']).prod() - 1
    
    print(f"\nüìà M√âTRICAS GENERALES:")
    print(f"   Tasa de √©xito: {tasa_exito:.2%}")
    print(f"   Retorno promedio por operaci√≥n: {retorno_promedio:.2%}")
    print(f"   Retorno total acumulado: {retorno_total:.2%}")
    
    # M√©tricas por horizonte
    print(f"\nüìä M√âTRICAS POR HORIZONTE:")
    for horizonte in sorted(df_operaciones['horizonte'].unique()):
        ops_horizonte = df_operaciones[df_operaciones['horizonte'] == horizonte]
        if len(ops_horizonte) > 0:
            exito_h = ops_horizonte['exito'].mean()
            retorno_h = ops_horizonte['retorno'].mean()
            n_ops = len(ops_horizonte)
            print(f"   {horizonte}h: {n_ops} ops, √âxito={exito_h:.2%}, "
                  f"Retorno={retorno_h:.2%}")
    
    # M√©tricas por calidad
    print(f"\nüéØ M√âTRICAS POR CALIDAD:")
    if 'probabilidad_calidad' in df_operaciones.columns:
        df_operaciones['calidad_alta'] = df_operaciones['probabilidad_calidad'] > 0.6
        df_operaciones['calidad_media'] = (
            (df_operaciones['probabilidad_calidad'] >= 0.4) & 
            (df_operaciones['probabilidad_calidad'] <= 0.6)
        )
        df_operaciones['calidad_baja'] = df_operaciones['probabilidad_calidad'] < 0.4
        
        for calidad, label in [('calidad_alta', 'Alta'), 
                              ('calidad_media', 'Media'), 
                              ('calidad_baja', 'Baja')]:
            ops_calidad = df_operaciones[df_operaciones[calidad]]
            if len(ops_calidad) > 0:
                exito_c = ops_calidad['exito'].mean()
                retorno_c = ops_calidad['retorno'].mean()
                print(f"   Calidad {label}: {len(ops_calidad)} ops, "
                      f"√âxito={exito_c:.2%}, Retorno={retorno_c:.2%}")
    
    # M√©tricas de gesti√≥n de riesgo
    print(f"\nüõ°Ô∏è M√âTRICAS DE GESTI√ìN DE RIESGO:")
    hit_sl_rate = df_operaciones['hit_sl'].mean()
    hit_tp_rate = df_operaciones['hit_tp'].mean()
    print(f"   Tasa de Stop Loss alcanzado: {hit_sl_rate:.2%}")
    print(f"   Tasa de Take Profit alcanzado: {hit_tp_rate:.2%}")
    
    # Sharpe Ratio (simplificado)
    if len(df_operaciones) > 1:
        sharpe_ratio = df_operaciones['retorno'].mean() / df_operaciones['retorno'].std() * np.sqrt(252 * 24)
        print(f"   Sharpe Ratio (anualizado): {sharpe_ratio:.2f}")
    
    # Drawdown m√°ximo
    retornos_acum = (1 + df_operaciones['retorno']).cumprod()
    max_acum = retornos_acum.expanding().max()
    drawdown = (retornos_acum - max_acum) / max_acum
    max_drawdown = drawdown.min()
    print(f"   M√°ximo drawdown: {max_drawdown:.2%}")
    
    return {
        'operaciones': df_operaciones,
        'resultados': resultados_backtest,
        'metricas': {
            'tasa_exito': tasa_exito,
            'retorno_promedio': retorno_promedio,
            'retorno_total': retorno_total,
            'hit_sl_rate': hit_sl_rate,
            'hit_tp_rate': hit_tp_rate,
            'max_drawdown': max_drawdown,
            'n_operaciones': len(df_operaciones)
        }
    }

# ============================================
# 6. SISTEMA DE TRADING EN TIEMPO REAL
# ============================================

class SistemaTrading:
    """
    Sistema de trading para ejecuci√≥n en tiempo real.
    """
    
    def __init__(self, modelos_entrenados, clasificador_calidad=None):
        self.modelos = modelos_entrenados['modelos_direccion']
        self.clasificador_calidad = clasificador_calidad
        self.ultima_actualizacion = None
    
    def analizar_activo(self, simbolo_activo):
        """
        Analiza un activo en tiempo real y retorna se√±ales si las hay.
        """
        try:
            # Descargar datos recientes
            fecha_fin = datetime.now(colombia_tz)
            fecha_inicio = fecha_fin - timedelta(days=30)  # √öltimos 30 d√≠as
            
            datos = yf.download(
                simbolo_activo,
                start=fecha_inicio,
                end=fecha_fin,
                interval=INTERVALO,
                progress=False
            )
            
            if datos.empty or len(datos) < 100:
                return None
            
            # Limpiar columnas MultiIndex si es necesario
            if isinstance(datos.columns, pd.MultiIndex):
                datos.columns = datos.columns.droplevel(1)
            
            # Calcular indicadores
            datos = calcular_indicadores_tecnicos(datos)
            
            # Obtener √∫ltima vela completa
            ultima_vela = datos.iloc[-2]  # -2 porque -1 podr√≠a estar incompleta
            
            if not ultima_vela['Anomalia']:
                return None
            
            # ============================================
            # EVALUAR SE√ëAL
            # ============================================
            
            precio = ultima_vela['Close']
            atr = ultima_vela['ATR']
            senal_mr = ultima_vela['Senal_MR']
            
            # Calcular niveles de riesgo
            niveles = calcular_niveles_riesgo_atr(precio, atr, senal_mr)
            
            # Filtrar por ratio R:R m√≠nimo
            if niveles['ratio_rr'] < RATIO_MINIMO_RR:
                return None
            
            # ============================================
            # PREDICCIONES POR HORIZONTE
            # ============================================
            
            predicciones = {}
            score_alineamiento = 0
            
            for horizonte in self.modelos.keys():
                modelo_info = self.modelos[horizonte]
                # Preparar features para predicci√≥n
                features_actual = []
                for feature in FEATURES_TECNICAS:
                    if feature in ultima_vela.index:
                        features_actual.append(ultima_vela[feature])
                    else:
                        features_actual.append(0)
                
                features_actual = np.array(features_actual).reshape(1, -1)
                features_scaled = modelo_info['scaler'].transform(features_actual)
                
                # Predecir
                pred_proba = modelo_info['modelo'].predict_proba(features_scaled)[0, 1]
                prediccion = 'LONG' if pred_proba > 0.5 else 'SHORT'
                alineado = 1 if prediccion == senal_mr else 0
                
                predicciones[horizonte] = {
                    'prediccion': prediccion,
                    'probabilidad': pred_proba,
                    'alineado': alineado
                }
                
                score_alineamiento += alineado
            
            score_alineamiento = (score_alineamiento / len(predicciones)) * 100
            
            # ============================================
            # EVALUAR CALIDAD
            # ============================================
            
            probabilidad_calidad = 0.5
            
            if self.clasificador_calidad is not None and isinstance(self.clasificador_calidad, dict):
                # Preparar features para clasificador de calidad
                features_calidad_actual = []
                for feature in FEATURES_CALIDAD:
                    if feature in ultima_vela.index:
                        features_calidad_actual.append(ultima_vela[feature])
                    elif feature == 'Ratio_RR':
                        features_calidad_actual.append(niveles['ratio_rr'])
                    else:
                        features_calidad_actual.append(0)
                
                features_calidad_actual = np.array(features_calidad_actual).reshape(1, -1)
                features_scaled = self.clasificador_calidad['scaler'].transform(features_calidad_actual)
                probabilidad_calidad = self.clasificador_calidad['modelo'].predict_proba(features_scaled)[0, 1]
            
            # ============================================
            # CONSTRUIR SE√ëAL
            # ============================================
            
            se√±al = {
                'activo': simbolo_activo,
                'fecha': ultima_vela.name,
                'senal_mr': senal_mr,
                'precio': precio,
                'atr': atr,
                'niveles_riesgo': niveles,
                'score_alineamiento': score_alineamiento,
                'probabilidad_calidad': probabilidad_calidad,
                'predicciones': predicciones,
                'intensidad_anomalia': ultima_vela['Intensidad_Anomalia']
            }
            
            return se√±al
            
        except Exception as e:
            print(f"‚ùå Error analizando {simbolo_activo}: {e}")
            return None
    
    def generar_alerta(self, se√±al, umbral_calidad=0.6):
        """
        Genera alerta de trading si la se√±al supera umbral de calidad.
        """
        if se√±al['probabilidad_calidad'] < umbral_calidad:
            return None
        
        mensaje = f"""üö® *SE√ëAL DE TRADING VALIDADA*

üìä *Activo:* {se√±al['activo']}
üìÖ *Fecha:* {se√±al['fecha'].strftime('%Y-%m-%d %H:%M')}
üí∞ *Precio:* ${se√±al['precio']:,.2f}
üéØ *Se√±al Mean Reversion:* {se√±al['senal_mr']}

ü§ù *Alineamiento Modelos:* {se√±al['score_alineamiento']:.0f}%
‚úÖ *Calidad Anomal√≠a:* {se√±al['probabilidad_calidad']:.0%}
üìä *Intensidad Anomal√≠a:* {se√±al['intensidad_anomalia']:.2f}œÉ

üí∞ *GESTI√ìN DE RIESGO:*
  üõë *Stop Loss:* ${se√±al['niveles_riesgo']['stop_loss']:,.2f}
  üéØ *Take Profit:* ${se√±al['niveles_riesgo']['take_profit']:,.2f}
  üìâ *Riesgo:* ${se√±al['niveles_riesgo']['riesgo']:,.2f}
  üìà *Recompensa:* ${se√±al['niveles_riesgo']['recompensa']:,.2f}
  ‚öñÔ∏è *R:R Ratio:* {se√±al['niveles_riesgo']['ratio_rr']:.2f}:1
  üìä *ATR:* {se√±al['atr']:.4f} ({se√±al['atr']/se√±al['precio']*100:.2f}%)

*PREDICCIONES POR HORIZONTE:*
"""
        
        for horizonte, pred in se√±al['predicciones'].items():
            icono = "‚úÖ" if pred['alineado'] else "‚ö†Ô∏è"
            mensaje += f"  {icono} *{horizonte}h:* {pred['prediccion']} ({pred['probabilidad']:.0%})\n"
        
        # Recomendaci√≥n basada en score
        if se√±al['score_alineamiento'] >= 70 and se√±al['probabilidad_calidad'] >= 0.7:
            recomendacion = "FUERTE SE√ëAL - CONSIDERAR OPERACI√ìN"
        elif se√±al['score_alineamiento'] >= 50 and se√±al['probabilidad_calidad'] >= 0.6:
            recomendacion = "SE√ëAL MODERADA - MONITOREAR"
        else:
            recomendacion = "SE√ëAL D√âBIL - ESPERAR MEJOR OPORTUNIDAD"
        
        mensaje += f"\nüí° *Recomendaci√≥n:* {recomendacion}"
        
        return mensaje

# ============================================
# 7. FUNCI√ìN PRINCIPAL DE EJECUCI√ìN
# ============================================

def main():
    """
    Funci√≥n principal que ejecuta todo el pipeline.
    """
    print("=" * 80)
    print("INICIANDO SISTEMA DE TRADING CON BACKTESTING")
    print("=" * 80)
    
    # Paso 1: Entrenar modelos con validaci√≥n walk-forward
    print("\nüéØ ENTRENANDO MODELOS CON VALIDACI√ìN WALK-FORWARD...")
    resultados_entrenamiento = pipeline_entrenamiento_completo()
    
    if resultados_entrenamiento is None:
        print("‚ùå Error en el entrenamiento. Saliendo...")
        return
    
    # Verificar que tenemos modelos entrenados
    if not resultados_entrenamiento['modelos_direccion']:
        print("‚ùå No se pudieron entrenar modelos de direcci√≥n. Saliendo...")
        return
    
    # Paso 2: Ejecutar backtesting de 3 meses
    print("\nüî¨ EJECUTANDO BACKTESTING RIGUROSO...")
    resultados_backtest = ejecutar_backtesting(
        resultados_entrenamiento['modelos_direccion'],
        resultados_entrenamiento['clasificador_calidad']
    )
    
    # Paso 3: Evaluar si el sistema es viable
    if resultados_backtest:
        metricas = resultados_backtest['metricas']
        
        print("\n" + "=" * 80)
        print("EVALUACI√ìN DE VIABILIDAD DEL SISTEMA")
        print("=" * 80)
        
        # Criterios de viabilidad
        criterios_cumplidos = 0
        total_criterios = 5
        
        # Criterio 1: Tasa de √©xito > 50%
        if metricas['tasa_exito'] > 0.5:
            print(f"‚úÖ Tasa de √©xito aceptable: {metricas['tasa_exito']:.2%}")
            criterios_cumplidos += 1
        else:
            print(f"‚ùå Tasa de √©xito baja: {metricas['tasa_exito']:.2%}")
        
        # Criterio 2: Retorno positivo
        if metricas['retorno_total'] > 0:
            print(f"‚úÖ Retorno total positivo: {metricas['retorno_total']:.2%}")
            criterios_cumplidos += 1
        else:
            print(f"‚ùå Retorno total negativo: {metricas['retorno_total']:.2%}")
        
        # Criterio 3: Drawdown controlado (< 20%)
        if abs(metricas['max_drawdown']) < 0.2:
            print(f"‚úÖ Drawdown controlado: {metricas['max_drawdown']:.2%}")
            criterios_cumplidos += 1
        else:
            print(f"‚ùå Drawdown excesivo: {metricas['max_drawdown']:.2%}")
        
        # Criterio 4: Suficientes operaciones
        if metricas['n_operaciones'] >= 20:
            print(f"‚úÖ Suficientes operaciones: {metricas['n_operaciones']}")
            criterios_cumplidos += 1
        else:
            print(f"‚ùå Pocas operaciones: {metricas['n_operaciones']}")
        
        # Criterio 5: Hit TP > Hit SL
        if metricas['hit_tp_rate'] > metricas['hit_sl_rate']:
            print(f"‚úÖ TP/SL favorable: TP={metricas['hit_tp_rate']:.2%}, SL={metricas['hit_sl_rate']:.2%}")
            criterios_cumplidos += 1
        else:
            print(f"‚ùå TP/SL desfavorable: TP={metricas['hit_tp_rate']:.2%}, SL={metricas['hit_sl_rate']:.2%}")
        
        print(f"\nüìä RESUMEN VIABILIDAD: {criterios_cumplidos}/{total_criterios} criterios cumplidos")
        
        if criterios_cumplidos >= 3:
            print("üéØ SISTEMA CONSIDERADO VIABLE - INICIANDO MONITOREO EN TIEMPO REAL")
            
            # Paso 4: Iniciar sistema en tiempo real
            sistema = SistemaTrading(
                resultados_entrenamiento,
                resultados_entrenamiento['clasificador_calidad']
            )
            
            print("\n" + "=" * 80)
            print("MONITOREO EN TIEMPO REAL")
            print("=" * 80)
            
            # Analizar cada activo
            for activo in ACTIVOS:
                print(f"\nüîç Analizando {activo} en tiempo real...")
                se√±al = sistema.analizar_activo(activo)
                
                if se√±al:
                    alerta = sistema.generar_alerta(se√±al, umbral_calidad=0.6)
                    if alerta:
                        print("\n" + "=" * 80)
                        print("üö® SE√ëAL DETECTADA!")
                        print("=" * 80)
                        print(alerta)
                        
                        # Aqu√≠ podr√≠as agregar env√≠o a Telegram
                        enviar_telegram(alerta)
                    else:
                        print(f"‚úÖ {activo}: Anomal√≠a detectada pero no supera umbral de calidad")
                else:
                    print(f"‚úÖ {activo}: Sin anomal√≠as significativas")
        else:
            print("‚ö†Ô∏è SISTEMA NO VIABLE - REQUIERE AJUSTES")
            print("   Recomendaciones:")
            print("   1. Ajustar par√°metros de Mean Reversion")
            print("   2. Revisar features t√©cnicas")
            print("   3. Considerar diferentes activos")
            print("   4. Ajustar gesti√≥n de riesgo")
    else:
        print("‚ùå No se pudo ejecutar backtesting. Revisar datos.")

# ============================================
# 8. FUNCI√ìN DE ENV√çO A TELEGRAM (OPCIONAL)
# ============================================

def enviar_telegram(mensaje, bot_token=None, chat_id=None):
    """
    Env√≠a mensaje por Telegram.
    """
    if not bot_token or not chat_id:
        # Intentar obtener de variables de entorno
        bot_token = os.getenv('BOT_TOKEN')
        chat_id = os.getenv('CHAT_ID')
    
    if not bot_token or not chat_id:
        print("‚ö†Ô∏è Credenciales de Telegram no configuradas")
        return False
    
    try:
        url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
        payload = {
            "chat_id": chat_id,
            "text": mensaje,
            "parse_mode": "Markdown",
            "disable_web_page_preview": True
        }
        
        response = requests.post(url, json=payload, timeout=10)
        return response.status_code == 200
    except Exception as e:
        print(f"‚ùå Error enviando a Telegram: {e}")
        return False

# ============================================
# 9. EJECUCI√ìN DEL SISTEMA
# ============================================

if __name__ == "__main__":
    # Verificar que tenemos datos suficientes
    print(f"üìÖ Fecha actual: {FECHA_ACTUAL}")
    print(f"üìÖ Inicio backtesting: {FECHA_INICIO_BACKTEST}")
    print(f"üìÖ Inicio entrenamiento: {FECHA_INICIO_ENTRENAMIENTO}")
    
    # Ejecutar sistema principal
    main()
    
    print("\n" + "=" * 80)
    print("SISTEMA COMPLETADO")
    print("=" * 80)
    print("Caracter√≠sticas implementadas:")
    print("‚úÖ Validaci√≥n Walk-Forward real")
    print("‚úÖ Logistic Regression regularizada (L2)")
    print("‚úÖ Eliminaci√≥n de m√©tricas in-sample")
    print("‚úÖ Sistema de scoring probabil√≠stico continuo")
    print("‚úÖ Arquitectura modular y escalable")
    print("‚úÖ Backtesting de 3 meses")
    print("‚úÖ Eliminaci√≥n de look-ahead bias")
    print("‚úÖ Gesti√≥n de riesgo basada en ATR")
    print("=" * 80)
